\renewcommand{\theequation}{\arabic{equation}}
\setcounter{equation}{0}


\textbf{\LARGE osn 23. Ансамбли в машинном обучении: комитеты, бэггинг, бустинг, стекинг. Алгоритм градиентного бустинга и его параметры.}  \\
\textbf{Ансамблем} (Ensemble, Multiple Classifier System) называется алгоритм, который состоит из нескольких алгоритмов машинного обучения, а процесс построения ансамбля называется \textbf {ансамблированием} (ensemble learning). Простейший пример ансамбля в регрессии – усреднение нескольких алгоритмов:

\begin{equation}\label{first}
a(x) = \frac{1}{n}(b_1(x)+...+b_n(x))
\end{equation}

Алгоритмы из которых состоит ансамбль (в \ref{first}) называются \textbf{базовыми алгоритмами} (base learners). Если рассматривать значения базовых алгоритмов на объекте  как независимые случайные величины с одинаковым матожиданием  и одинаковой конечной дисперсией, то понятно, что случайная величина \ref{first} имеет такое же матожидание, но меньшую дисперсию:
\begin{equation}
    \xi = \frac{1}{n}(\xi_1+...+\xi_n) 
\end{equation}
\begin{equation}
    \mathbb{E}\xi=\frac{1}{n}(\mathbb{E}\xi_1+...+\mathbb{E}\xi_n)=\mathbb{E}\xi_i
\end{equation}
\begin{equation}
    \mathbb{D}\xi=\frac{1}{n^2}(\mathbb{D}\xi_1+...+\mathbb{D}\xi_n)=\frac{\mathbb{D}\xi_i}{n}
\end{equation}

В задачах классификации простейший пример ансамбля – \textbf{комитет большинства}:
\begin{equation}\label{komitet}
a(x) = mode(b_1(x)+...+b_n(x))
\end{equation}
где  \textbf{mode} – мода (значение, которое встречается чаще других среди аргументов функции). 

Большинство приёмов в прикладном ансамблировании направлено на то, чтобы ансамбль был «достаточно разнообразным», тогда ошибки отдельных алгоритмов на отдельных объектах будут компенсироваться корректной работой других алгоритмов. 

\textbf{Бэггинг(Bagging)}
Идея бэггинга (bootstrap aggregating) проста: каждый базовый алгоритм обучается на случайном подмножестве обучающей выборки. В этом случае, даже используя одну модель алгоритмов, мы получаем различные базовые алгоритмы. Есть следующие реализации описанной идеи. \\
\textbf{Бутстрэп} --- универсальный инструмент для оценки статистической точности.
\begin{center}
\begin{tabular}{l|l} 
    \hline\hline
    Метод  & Описание \\
     \hline\hline
    Бэгинг  & Подвыборка обучающей выборки \\
     & берётся с помощью бутстрепа \\
     \hline
    Случайные подпространства & Случайное подмножество признаков \\
    (Random Subspaces) & \\
    \hline
    Случайные патчи & Одновременно берём случайное подмножество \\
    (Random Patches) & объектов и признаков

 \end{tabular}
\end{center}

Бэгинг позволяет получать т.н. out-of-bag(OOB)-ответы модели. Идея очень простая: каждый алгоритм обучается на подвыборке, в неё, вообще говоря, попадают не все объекты их обучения, поэтому на остальных объектах можно узнать ответы алгоритма. При достаточном числе базовых алгоритмов мы таким образом оцениваем ответ почти на всех объектах обучения. При этом это «честный» ответ: те алгоритмы, которые участвовали в его формировании «не видели» истинной метки соответствующего объекта.

Аналогично оценивается out-of-bag(OOB)-ошибка бэгинга. Можно оценить ошибку с помощью полученных  OOB-ответов, но чаще делают проще: для каждого базового алгоритма ошибку оценивают на объектах, не попавших в его обучение, а затем ошибки усредняют.

\textbf{Бустинг (Boosting)}
Главная идея бустинга – базовые алгоритмы строятся не независимо, каждый следующий мы строим так, чтобы он исправлял ошибки предыдущих и повышал качество всего ансамбля. Пусть, например, решается задача регрессии с функцией ошибки $L(y, a)$. Предположим, мы уже построили алгоритм a(x), теперь строим b(x) таким образом, чтобы
\begin{equation}
    \displaystyle\sum_{i=1}^{m} L(y_i, a(x_i) + b(x_i)) \xrightarrow{} min
\end{equation}
где $y_i$ - истинная метка, $x_i$-признаки i-го объекта выборки.
Особенность терминологии, когда говорят о бустинге следующая. Базовые алгоритмы называются \textbf{«слабыми»} (weak learners),  а ансамбль – \textbf{«сильным»} алгоритмом (strong learner).

\textbf{Стекинг (stacking)} — алгоритм ансамблирования:
\begin{itemize}
    \item результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения)
\end{itemize}
Он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия. \\
\textbf{Градиентный бустинг и его параметры} Предположим, что решается задача машинного обучения (для простоты можно считать, что регрессии) с обучающей выборкой $(x_i, y_i), i=1,...,m$, и дифференцируемой функцией ошибки $L(y, a)$. Мы построили алгоритм $a(x)$, давайте теперь построим алгоритм $b(x)$ такой, что $a(x_i)+b(x_i)=y_i, i \in \{1,2,...m\}.$
Такой алгоритм осуществляет поправку ответов алгоритма $a(x)$ до верных ответов на обучающей выборке, т.е. на невязку $\varepsilon_i = y_i - a(x_i)$. 
Главный вопрос здесь – как обучить второй алгоритм. Вообще говоря, нельзя считать, что мы получили новую задачу с обучающей выборкой $(x_i, \varepsilon_i), i=1,...,m$ и функцией ошибки $L(y, a)$, поскольку наша задача 
\begin{equation}\label{1}
    \displaystyle\sum_{i=1}^{m} L(y_i, a(x_i) + b(x_i)) \xrightarrow{} min
\end{equation}
может отличаться от решения
\begin{equation}\label{2}
    \displaystyle\sum_{i=1}^{m} L(y_i - a(x_i), b(x_i)) \xrightarrow{} min
\end{equation}
Хотя, справедливости ради, заметим, что для большинства разумных функций ошибок записи \ref{1} и \ref{2} эквивалентны. \\
Не всегда \ref{1} решается аналитически (из-за достаточно сложных функций ошибок). Перепишем \ref{1} в таком виде 
\begin{equation}\label{3}
    F = \displaystyle\sum_{i=1}^{m} L(y_i, a(x_i) + b_i) \xrightarrow{} \min_{(b_1, ..., b_m)}
\end{equation}
если рассматривать эту задачу как задачу минимизации функции $F(b_1, ..., b_m)$, то полезно вспомнить, что функция многих переменных максимально убывает в направлении своего антиградиента: 
\begin{equation}\label{4}
    -(L'(y_1, a(x_1)),..., L'(y_m, a(x_m))),
\end{equation}
здесь производная берётся по второму аргументу. Получается, что выгодно считать
\begin{equation}\label{5}
    b_i = -(L'(y_i, a(x_i))), i \in \{1,2,...m\},
\end{equation}
а это и есть ответы нашего алгоритма b. Получается, что его следует настраивать на обучающей выборке 
\begin{equation}\label{6}
   (x_i, -L'(y_i, a(x_i))), i \in \{1,2,...m\},
\end{equation}
Из выражения \ref{6} понятно будет название – градиентный бустинг. 
Итак, мы научились строить алгоритм b, который корректирует ответы алгоритма a. Понятно, что и сумма этих алгоритмов может иметь значительную ошибку, но можно построить третий алгоритм, который корректирует эту сумму. Процесс построения можно продолжить. Получаем классический алгоритм градиентного бустинга. \\


Перечислим \textbf{параметры градиентного бустинга} в современных реализациях:
\begin{itemize}
    \item Параметры, определяющие задачу: \\
        -objective – какая задача решается и в каком формате будет ответ \\
        -loss – функция ошибки для минимизации \\
        -eval\_metric – значения какой функции ошибки смотреть на контроле \\
    \item Основные параметры: \\
    -learning\_rate – темп (скорость) обучения \\
    -num\_iterations / n\_estimators  – число итераций бустинга \\
    -early\_stopping\_round  –  если на отложенном контроле заданная функция ошибки не уменьшается такое число итераций, обучение останавливается
    -init – какой алгоритм использовать в качестве первого базисного (именно его ответы будет улучшать бустинг)
    --booster – какой бустинг проводить: над решающими деревьями или линейный \\
    -grow\_policy – порядок построения дерева: на следующем шаге расщеплять вершину, ближайшую к корню, или на которой ошибка максимальна\\
    \item Параметры регуляризации
    
    
\end{itemize}


Ссылки на используемые материалы:
\begin{itemize}
    \item \href{https://alexanderdyakonov.wordpress.com/2019/04/19/%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B8-%D0%B2-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8}{Ансамбли в машинном обучении, сайт Дьяконова}
    \item \href{https://academy.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii}{Ансамбли в машинном обучении, учебник по машинному обучению Яндекса}
    \item \href{https://alexanderdyakonov.wordpress.com/2017/03/10/c%d1%82%d0%b5%d0%ba%d0%b8%d0%bd%d0%b3-stacking-%d0%b8-%d0%b1%d0%bb%d0%b5%d0%bd%d0%b4%d0%b8%d0%bd%d0%b3-blending/}{Стеккинг, Блендинг, сайт Дьяконова}
    \item \href{http://dyakonov.org/2017/06/09/%d0%b3%d1%80%d0%b0%d0%b4%d0%b8%d0%b5%d0%bd%d1%82%d0%bd%d1%8b%d0%b9-%d0%b1%d1%83%d1%81%d1%82%d0%b8%d0%bd%d0%b3/}{ГРАДИЕНТНЫЙ БУСТИНГ, Дьяконов}
\end{itemize}


