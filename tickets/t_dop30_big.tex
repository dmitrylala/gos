\setcounter{section}{4}
\setcounter{subsection}{30}
\setcounter{equation}{0}
\textbf{\LARGE dop 30. Виды параллельной обработки данных. Компьютеры с общей и распределенной памятью. Производительность вычислительных систем, методы оценки и измерения.}\\

Виды параллельной обработки данных:
\begin{itemize}
    \item Параллельная обработка
    \item Конвейерная обработка
\end{itemize}

При параллельной обработке несколько независимых устройств выполняют какую-то задачу (увеличение производительности достигается за счет количества независимо работающих устройств).\\
При конвейерной обработке процесс разбивается на некоторые этапы, которые выполняются последовательно. Выйгрыш в производительности достигается за счет совмещения операций, которые ранее могли быть разнесены во времени. Для конвейерной обрабоки существует некоторая задержка для того, чтобы заполнить все этапы, но после заполнения всех этапов происходит ускорение обработки. $T = L + (N - 1)$, где $T$ - общее время обработки, $L$ - число ступеней конвейера, $N$ - размер входных данных.\\

\begin{wrapfigure}{r}{0.25\textwidth}
    \centering
    \includegraphics[width=0.25\textwidth]{pics/smp-computer.png}
\end{wrapfigure}

Компьютеры с общей памятью (SMP - Shared Memory Processors / Symmetric MultiProcessor), в SMP-компьютерах все, кроме процессоров, в одном экземпляре: образ ОС, память, подсистема ввода-вывода.\\
Плюс - относительная простота параллельного программирования
Минус - сложность увеличения числа процессоров (роста производительности)\\


\begin{wrapfigure}{r}{0.25\textwidth}
    \centering
    \includegraphics[width=0.25\textwidth]{pics/distributed-memory-computer.png}
\end{wrapfigure}

Компьютеры с распределенной памятью состоят из вычислительных узлов, каждый из которых является полноценным компьютером со своей памятью, ОС, устройствами ввода-вывода и т.п., взаимодействующих друг с другом через коммуникационную среду.\\
Плюс - относительная простота увеличения числа процессоров (роста производительности)\\
Минус - сложность параллельного программирования.\\

Основные показатели эффективности:\\
\begin{itemize}
    \item $p$ - число процессоров
    \item $T_{1}$ - время работы программы на одном процессоре
    \item $T_{p}$ - время работы программы на $p$ процессорах
    \item $S = T_{1} / T_{p}$ - ускорение (speedup) выполнения распараллеленной программы на $p$ процессорах (если $S = p$ - линейное ускорение, если $S > p$ - суперлинейное ускорение)
    \item Эффективность реализации - $R_{max} / R_{peak}$ - отношение реальной производительности к пиковой производительности (тк пиковая производительность на практике недостижима, то эффективность реализации всегда меньше 1)
    \item Эффективность распараллеливания $E = S / p$ - определяет среднюю долю времени выполнения параллельного алгоритма, в течение которого процессоры реально используются для решения задачи
    \item Стоимость вычислений - $C = pT_{p}$
    \item $T_{0} = pT_{p} - T_{1}$ - суммарные накладные расходы
    \item Масштабируемость (scalability) - способность системы увеличивать свою производительность при добавлении ресурсов. Вертикальная масштабируемость - замена платформы, в которой функционирует система на новую, с большей производительностью. Горизонтальная масштабируемость - увеличение производительности за счет добавления дополнительных программных или аппаратных средств
    \item $W$ - вычислительная сложность задачи (кол-во основных вычислительных шагов лучшего последовательного алгоритма, необходимого для решения задачи на одном процессоре)
    \item Сильная масштабируемость - зависимость производительности $R$ от количества процессоров при фиксированной вычислительной сложности ($W = const$)
    \item Масштабируемость вширь (wide scaling) - зависимость производительности $R$ от вычислительной сложности задачи $W$ при фиксированном числе процессоров ($p = const)$
    \item Слабая масштабируемость (weak scaling) — зависимость производительности $R$ от количества процессоров $p$ при фиксированной вычислительной сложности задачи в пересчёте на один процессор ($W/p = const$).
\end{itemize}

% -------- source --------
\bigbreak
[\cite{super_computers_lections} слайды 121-128, 191-193, 158-183]